{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=kCc8FmEb1nY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115393,\n",
       " \"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "path_in = \"data/shakespeare.txt\"\n",
    "with open(path_in, 'r') as fh:\n",
    "    text = fh.read().strip()\n",
    "len(text), text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42], 'hello world')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda text: [stoi[ch] for ch in text]\n",
    "decode = lambda ids: ''.join(itos[i] for i in ids)\n",
    "encode(\"hello world\"), decode(encode(\"hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115393]),\n",
       " torch.int64,\n",
       " tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "         53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "          1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "         57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "          6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "         58, 47, 64, 43, 52, 10,  0, 37, 53, 59]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To tensor\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data.shape, data.dtype, data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003853, 111540)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsets split\n",
    "n = int(len(data) * 0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]),\n",
       " torch.Size([4, 8]),\n",
       " tensor([[54, 43, 39, 49,  1, 39, 45, 39],\n",
       "         [43, 56, 57, 11,  1, 61, 46, 53],\n",
       "         [43,  1, 46, 39, 58, 46,  1, 58],\n",
       "         [43,  1, 47, 57,  1, 57, 53,  1]]),\n",
       " tensor([[43, 39, 49,  1, 39, 45, 39, 47],\n",
       "         [56, 57, 11,  1, 61, 46, 53,  6],\n",
       "         [ 1, 46, 39, 58, 46,  1, 58, 56],\n",
       "         [ 1, 47, 57,  1, 57, 53,  1, 50]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batching\n",
    "torch.manual_seed(42)\n",
    "block_size = 8 # max context length\n",
    "batch_size = 4 # max parallely processed examples\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    starts = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in starts])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in starts])\n",
    "    return x, y\n",
    "\n",
    "batch_x, batch_y = get_batch('train')\n",
    "batch_x.shape, batch_y.shape, batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.7187, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nuoiaF$z\\nM?kI;h\\nDbuMG,H3LYNmrDxKgTpvAKOF-jU.hc;fBMTGa-IS\\ng3lEb&ZQ,l;:m;lpcNN\\nKpVEYRIIM,'hCRbMAcWTkrnH\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None): # idx.shape == targets.shape == batch_size x block_size [4, 8]\n",
    "        logits = self.token_embedding_table(idx) # tensor batch_size x block_size x vocab_size [4, 8, 65] ~ [Batch, Time, Channel]\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets) # https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy, negative log likelihood\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :] # [B,T,C] -> [B,C] for last Time step\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # [B,C] -> [B,1]; take 1 random C for each B\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # [B,T+1]\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(batch_x, batch_y)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.long) # 0 == \\n\n",
    "decode(m.generate(idx, max_new_tokens=100)[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate loss\n",
    "eval_iters = 200\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = m(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:        0, train loss:  2.46986, eval loss:  2.48891\n",
      "Step:      200, train loss:  2.46441, eval loss:  2.48163\n",
      "Step:      400, train loss:  2.47061, eval loss:  2.48342\n",
      "Step:      600, train loss:  2.46372, eval loss:  2.47555\n",
      "Step:      800, train loss:  2.46449, eval loss:  2.48814\n",
      "Step:     1000, train loss:  2.46199, eval loss:  2.48468\n",
      "Step:     1200, train loss:  2.45904, eval loss:  2.48919\n",
      "Step:     1400, train loss:  2.45831, eval loss:  2.47194\n",
      "Step:     1600, train loss:  2.45307, eval loss:  2.47909\n",
      "Step:     1800, train loss:  2.46323, eval loss:  2.48977\n",
      "Step:     2000, train loss:  2.46453, eval loss:  2.47476\n",
      "Step:     2200, train loss:  2.45728, eval loss:  2.47103\n",
      "Step:     2400, train loss:  2.45310, eval loss:  2.47943\n",
      "Step:     2600, train loss:  2.44857, eval loss:  2.48196\n",
      "Step:     2800, train loss:  2.46144, eval loss:  2.49010\n",
      "Step:     3000, train loss:  2.46358, eval loss:  2.48035\n",
      "Step:     3200, train loss:  2.45377, eval loss:  2.48171\n",
      "Step:     3400, train loss:  2.45671, eval loss:  2.47680\n",
      "Step:     3600, train loss:  2.44540, eval loss:  2.47664\n",
      "Step:     3800, train loss:  2.45639, eval loss:  2.47917\n",
      "Step:     4000, train loss:  2.45289, eval loss:  2.48105\n",
      "Step:     4200, train loss:  2.45296, eval loss:  2.48108\n",
      "Step:     4400, train loss:  2.45758, eval loss:  2.48778\n",
      "Step:     4600, train loss:  2.45389, eval loss:  2.47171\n",
      "Step:     4800, train loss:  2.44848, eval loss:  2.48899\n",
      "Step:     5000, train loss:  2.45719, eval loss:  2.47592\n",
      "Step:     5200, train loss:  2.45445, eval loss:  2.48660\n",
      "Step:     5400, train loss:  2.45713, eval loss:  2.47917\n",
      "Step:     5600, train loss:  2.45146, eval loss:  2.48548\n",
      "Step:     5800, train loss:  2.45767, eval loss:  2.49170\n",
      "Step:     6000, train loss:  2.45208, eval loss:  2.47861\n",
      "Step:     6200, train loss:  2.46256, eval loss:  2.46716\n",
      "Step:     6400, train loss:  2.45630, eval loss:  2.47185\n",
      "Step:     6600, train loss:  2.45222, eval loss:  2.47998\n",
      "Step:     6800, train loss:  2.46488, eval loss:  2.47975\n",
      "Step:     7000, train loss:  2.45829, eval loss:  2.48823\n",
      "Step:     7200, train loss:  2.45743, eval loss:  2.48636\n",
      "Step:     7400, train loss:  2.45184, eval loss:  2.47655\n",
      "Step:     7600, train loss:  2.45061, eval loss:  2.48753\n",
      "Step:     7800, train loss:  2.45728, eval loss:  2.48871\n",
      "Step:     8000, train loss:  2.45180, eval loss:  2.48262\n",
      "Step:     8200, train loss:  2.45312, eval loss:  2.47564\n",
      "Step:     8400, train loss:  2.45341, eval loss:  2.48052\n",
      "Step:     8600, train loss:  2.45394, eval loss:  2.48495\n",
      "Step:     8800, train loss:  2.44982, eval loss:  2.48785\n",
      "Step:     9000, train loss:  2.45395, eval loss:  2.49250\n",
      "Step:     9200, train loss:  2.44827, eval loss:  2.48397\n",
      "Step:     9400, train loss:  2.45016, eval loss:  2.48754\n",
      "Step:     9600, train loss:  2.45988, eval loss:  2.48264\n",
      "Step:     9800, train loss:  2.46073, eval loss:  2.48455\n",
      "2.5767219066619873\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "batch_size = 32\n",
    "for i in range(10_000):\n",
    "\n",
    "    if i % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step: {i:8}, train loss: {losses['train']:8.5f}, eval loss: {losses['val']:8.5f}\")\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDKVam&K3ZnkIMaqntjh-AW'BJxxghjZTBCnCU?qBQbwyCjhRhSLyJfGtsutJBy-j&,r,'k$PTuZm3tPbu NwH-IPeaquJVrK'x fK-d3si'g.cu,k-JMiv?R-jlqIeNiaqan\\n3VEmtWcEIcO!bAFDHhSsYzEn;UGI;f .bYh,g:gSOr:s3axTBykJG.!gsz ffgpGLHa3xDkWlrwVm3C\\nKh.H?Hvy!ogQahk!DmgTZ&X.SkmWdkovk?qKpjvTWPSJNzB?qn usMXFU.cYFAWVkJI-JP\\nLwmLBgBNiyZuLietbGFfUN?AFDINUBGiZBtKpt;LuoERDPImKHh!TwVTyy.lWC:ZKp-r!MV!vVoivkX yUROKGczW'scCR;QN?umaTozJCfhSnDc.cJnQWkkqIaqfSesGnx'dO;cdC YVeYRpIYwcGPeuv.fBy:mMKTwXs-It,XhCh.;$oblc- YpqgB?-jhSkJMAFq\\n3sn';,blGtY?xNwT\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(m.generate(idx, max_new_tokens=500)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6]], dtype=torch.int32),\n",
       " tensor([[[1]],\n",
       " \n",
       "         [[2]],\n",
       " \n",
       "         [[3]],\n",
       " \n",
       "         [[4]],\n",
       " \n",
       "         [[5]],\n",
       " \n",
       "         [[6]]], dtype=torch.int32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor reshape - eg. flatten\n",
    "t = torch.tensor([[1,2,3], [4,5,6]], dtype=torch.int)\n",
    "t.view(3, 2), t.view(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch for attention\n",
    "torch.manual_seed(42)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 2]),\n",
       " tensor([[ 1.9269,  1.4873],\n",
       "         [ 0.9007, -2.1055],\n",
       "         [ 0.6784, -1.2345],\n",
       "         [-0.0431, -1.6047],\n",
       "         [-0.7521,  1.6487],\n",
       "         [-0.3925, -1.4036],\n",
       "         [-0.7279, -0.5594],\n",
       "         [-0.7688,  0.7624]]),\n",
       " tensor([[ 1.9269,  1.4873],\n",
       "         [ 1.4138, -0.3091],\n",
       "         [ 1.1687, -0.6176],\n",
       "         [ 0.8657, -0.8644],\n",
       "         [ 0.5422, -0.3617],\n",
       "         [ 0.3864, -0.5354],\n",
       "         [ 0.2272, -0.5388],\n",
       "         [ 0.1027, -0.3762]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute normalized average of all past tokens\n",
    "# context V1 loop\n",
    "# iterate over batches in time steps, keep all channels\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        x_prev = x[b, :t+1] # [t,C], take single b, all past t's and the entire C\n",
    "        xbow[b, t] = torch.mean(x_prev, 0) # 0 = t axis, 1 = C axis\n",
    "xbow.shape, x[0], xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "b=tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c=tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# context V2 matrix multiplication\n",
    "# upper triangular masking\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3)) # upper triangular masking\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print(f\"{a=}\")\n",
    "print(f\"{b=}\")\n",
    "print(f\"{c=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c=tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print(f\"{a=}\")\n",
    "print(f\"{b=}\")\n",
    "print(f\"{c=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 2]), True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T)) # [T,T]\n",
    "wei = wei / torch.sum(wei, 1, keepdim=True) # [T,T]\n",
    "xbow2 = wei @ x # [T,T] @ [B,T,C] -> can't multiply\n",
    "# so torch will auto expand to B to match dim0=B\n",
    "# batched matrix multiply\n",
    "# [B,T,T] @ [B,T,C] -> [B,T,C]\n",
    "xbow2.shape, torch.allclose(xbow, xbow2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context V3 softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # == cut out future tokens\n",
    "wei = F.softmax(wei, dim=-1) # normalization\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " tensor([[ 0.7630, -0.2412, -0.4150,  0.3833,  0.5740, -1.6738,  0.7954,  0.6872,\n",
       "          -0.3848,  0.5073, -0.5312, -0.1221,  0.0445,  1.2169,  0.9940,  1.5281],\n",
       "         [ 0.4894, -0.1269, -0.6833, -0.3046,  0.2735, -0.7042,  0.2440, -0.3779,\n",
       "          -0.1338,  0.3596,  0.1304,  0.0420,  0.1211,  0.6841,  0.5222,  0.2674],\n",
       "         [ 0.2229,  0.0217, -0.2720,  0.1393,  0.5338, -0.7021,  0.1438, -0.1945,\n",
       "          -0.3118,  0.3121,  0.0133, -0.1628, -0.3413,  0.5239,  0.7935,  0.6615],\n",
       "         [ 0.1464,  0.1534, -0.2507, -0.0095,  0.1002, -0.5184, -0.0287, -0.5144,\n",
       "          -0.2047,  0.2677,  0.0913,  0.1241,  0.1922,  0.5099,  0.3388,  0.2016],\n",
       "         [ 0.0442,  0.1569, -0.2724,  0.2373,  0.2169, -0.4894, -0.2219, -0.3260,\n",
       "          -0.0747,  0.1438, -0.0729,  0.0190, -0.0435,  0.3857,  0.3784,  0.2121],\n",
       "         [ 0.0259,  0.0879, -0.2091,  0.1253,  0.2116, -0.5392, -0.1011, -0.2242,\n",
       "          -0.1561,  0.1605,  0.0565,  0.0393,  0.0089,  0.3979,  0.3617,  0.2423],\n",
       "         [ 0.0500,  0.0649, -0.1406, -0.0490,  0.0701, -0.5600, -0.0259, -0.2827,\n",
       "          -0.2042,  0.1096,  0.0821, -0.0321,  0.0900,  0.3928,  0.2201,  0.2433],\n",
       "         [ 0.0270,  0.0104, -0.2592,  0.0401,  0.0213, -0.4398, -0.1968, -0.1274,\n",
       "           0.0034, -0.0648, -0.1583, -0.1440, -0.0360,  0.2762,  0.1757,  0.2135]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context V4 self attention\n",
    "torch.manual_seed(42)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C) # token private information\n",
    "\n",
    "# Single head\n",
    "head_size = 16\n",
    "query = nn.Linear(C, head_size, bias=False) # what am i looking for (autodetected pattern)\n",
    "key = nn.Linear(C, head_size, bias=False)  # what do I contain \n",
    "# if key and query are aligned, they create HIGH AFFINITY = interact to a high amount and they will cotribute more for current token as opposed to other tokes in the sequence\n",
    "value = nn.Linear(C, head_size, bias=False)  # filter for particular attention head\n",
    "\n",
    "# forward modules by x; parallel = no communication so far\n",
    "q = query(x) # [B,T,head_size]\n",
    "k = key(x)   # [B,T,head_size]\n",
    "\n",
    "# communincate:\n",
    "wei = q @ k.transpose(-2, -1) # [B,T,head_size] @ [B,head_size, T] -> [B,T,T] = for each batch, take learned time interactions between tokens\n",
    "wei = wei * head_size**-0.5 # scale attention - lessen the values so that softmax won't go to extremely low values (\"converge towards one-hot vectors\")\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T)) # B dim broadcasting\n",
    "# before wei was just zeros, now it's attention matrix\n",
    "# wei = torch.zeros(T,T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # we want or want not to discard future tokens, depeding on task\n",
    "wei = F.softmax(wei, dim=-1) # boosts high affinity\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out.shape, out[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention is \n",
    "- a communication method\n",
    "- a weighted sum of focus\n",
    "\n",
    "Self attention \n",
    "- same input x creates queries, keys and values\n",
    "\n",
    "Cross attention\n",
    "- different source of data - keys + values, own queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None): # idx.shape == targets.shape == batch_size x block_size [4, 8]\n",
    "        logits = self.token_embedding_table(idx) # tensor batch_size x block_size x vocab_size [4, 8, 65] ~ [Batch, Time, Channel]\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets) # https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy, negative log likelihood\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :] # [B,T,C] -> [B,C] for last Time step\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # [B,C] -> [B,1]; take 1 random C for each B\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # [B,T+1]\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13 (main, Sep 11 2023, 08:39:02) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89b2e8084823e03a90aeac42ca3e6d432c5ee69185c690a3bb8b23dbb0a561e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
